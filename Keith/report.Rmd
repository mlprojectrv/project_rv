---
title: "The Recividism rate"
author: "Keith Tung"
date: "April 2, 2019"
output:
  html_document:
    keep_md: TRUE
    TOC_float: TRUE
    code_folding: hide
    theme: united
    fig.height: 12
    fig.width: 12
    message: 'no'
    warning:  'no'
    alignment: center
---

```{r message = FALSE, warning = FALSE}
################################library##############################################
library(tidyverse)
library(readr)
library(ggplot2)
library(ggridges)
library(pander)
library(caret)
################################Read File############################################
dat_o <- read.csv('https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv')
dat <- read_csv('../dt_dat.csv')
rdat <- read_csv('../dt.csv') %>% select(-1)
frdat <- read_csv('../fr_race.csv') %>% select(-1)
fdat <- read_csv('../frw_race.csv') %>% select(-1)
```

![](https://s3.amazonaws.com/user-media.venngage.com/470824-9369c5da7d87766af4f57f6d0421e5e9.jpg)  

### Team Info
1. Team members: 
  Keaton Sant, Keith Tung, Juheon Song
2. Data source:
  Data source: Machine bias https://github.com/propublica/compas-analysis/blob/master/compas-scores-two-years.csv
    
# Introduction  
###    The source  
This project is mainly inspired by a statistical study online; in this study, the narrator introduces the reader to an algorithm the justice system in the US is currently using. This algorithm takes in information of a criminal, for instance, age, gender, race, and criminal records, then produces a score for the person’s ‘risk of recidivism’ which would be provided as reference to the judge in deciding the sentence of a criminal; the study contains paragraphs of argument, various plots and charts that surround the same claim : the algorithm is biased against black criminal.     

###     Our take  

We, as a team, chose to investigate this data that recorded inmates’ information that was used to predict recidivism rate before they were sentenced jail time. This data set shows a column with the predicted score and whether these individuals ended up committing a crime again in the 2 years period after they were released from jail.   

###    Our Goals  
There are two main goals for our project:  

*	Examine the claim made by the study, see that the current algorithm is biased
*	Try to create an algorithm hoping to see if race is indeed a helpful variable in predicting recidivism rate.
  
#  Data Preparation  
###    Understanding the data  
Fortunately, the study provided the data we need, and we were able to get our hands on a fairly clean dataset. The data consist of 53 columns and 10 observation.  
  
  
There are a few observations from the data.   
  

### Observation{.tabset}  
#### The converting
To accomplish our tasks, we needed the data to fit in four different machine learning algorithms, namely, Naïve Baynes (classifier), Decision tree (classifier), Neutral network classification, and lastly neutral network regression for the ensemble part. The data set contains numeric, categorical and nominal columns, with and binary target (recidivist or non-recidivist); we decided that we would have to convert our data to fit our models.   

#### Original data(sample of 5)
```{r}
dat_o %>% head(5) %>% print.data.frame()
```
#### Data after wrangling(decision tree)
```{r}
dat %>% head(5) %>% print.data.frame()
```
#### Data after wrangleing(Neutral Network and Naïve Baynes)
```{r}

```

###    Decisions made{.tabset}  
#### Charges
One of the challenges of the data is the c_charge_desc that stores the description of the crime for what the inmate was charged; there were 437 different charges description in our data with over 7000 observations. We had to do a local encoding for each of them for the neural network models.    

#### List of charges  
```{r}
dat_o$c_charge_desc %>% 
  unique() 
```




# Mining/learning from the data


### Data analysis{.tabset}  
#### 1  
The graph shows the density ofthe predicted score from the algorithm. We can see a that in all three age groups, african-americans has a higher density beyond the 5.0 in score; with non-african-american criminals having distrabutions closing to the other end. It also shows the differences among the age group, while the algorithm is fairly willing to give a low score to someone in the 'Greater than 45' group; it tends to give a higher score to people that are in the less than 25 more than the other two. 
```{r message = FALSE}
dat_o %>% 
  mutate(age_cat = fct_relevel(age_cat, 
                               c('Less than 25',
                                 '25 - 45',
                                 'Greater than 45'))) %>% 
  ggplot() +
  aes(y = age_cat, 
      x = dat_o$decile_score.1, 
      fill = (race == 'African-American')) +
  geom_density_ridges(panel_scaling = F,
                       alpha = 0.35) +
  coord_cartesian(xlim = c(0,10)) +
  scale_fill_brewer(palette = 'Dark2') +
  ggthemes::theme_pander() +
  labs(x = 'predicted score',
       y = 'age group') +
  guides(fill = guide_legend(title = 'African-American', label.position = 'right')) +
  theme(axis.line.x = element_line(linetype = 'dashed', colour = 'Gray'),
        legend.position = c(0.9,0.9))
```

#### 2  
```{r message = FALSE}
dat_o %>% 
  ggplot() +
  aes(x = dat_o$decile_score.1, fill = dat_o$two_year_recid== 1) +
  geom_histogram(position = 'dodge_2') +
  facet_grid(race == 'African-American'~.) +
  ggthemes::theme_pander() +
  theme(strip.text.y = element_text(size = 8, angle = 0),
        strip.background = element_blank()) +
  scale_fill_brewer(palette = 'Dark2') +
  guides(fill = guide_legend(title = 'recidivist', label.position = 'right')) +
  labs(x = 'predicted score', y = '') +
  theme(axis.line.x = element_line(linetype = 'dashed', colour = 'Gray'),
        legend.position = c(0.9,0.9)) 
  
```

#### 3
```{r}
dat_o %>% 
  ggplot() +
  aes(y = as.numeric(dat_o$two_year_recid), x = dat_o$decile_score.1) +
  geom_smooth(method = 'glm', method.args = list(family = 'binomial'), se = F, linetype = 'dashed') +
  geom_point() +
  ggthemes::theme_pander() +
  labs(y = 'probability', x = 'mpg')

dat_o %>% 
  filter(race == 'African-American') %>% 
  ggplot() +
  aes(y = as.numeric(two_year_recid), x = decile_score.1) +
  geom_smooth(method = 'glm', method.args = list(family = 'binomial'), se = F, linetype = 'dashed') +
  geom_point() +
  ggthemes::theme_pander() +
  labs(y = 'probability', x = 'mpg')
```

###    The planning  
We mainly used three algorithms for this project, decision tree, neural network, and naïve Baynes. Since we are trying to compare the given predicted score to ours, we were convinced that a regression is best for the task at hand, since the predicted scores are in a scale of 1 to 10. 1 being the inmates will not likely to commit crime in the future and 10 being very likely, our algorithms would suggest a number between 1 and 10 for the predicted, then we would find out how close/far the score is to the target (1 = 10, 0 = 0) compared with the given scores. We also wanted to see if the algorithm is discriminating against each group of people by their colour of skin. A way to find that out is to see the ratio of (false positive) type I error in the non-African-American cases and  African-American cases.  

###    Setting up the environment  
When we were trying the different algorithms, we would run our models in two environments, one with race given as the training data, the other one without race given. We would like to find out how important the race feature is. This means before the ensemble learning, we had 6 different models to building first.  

# Results{.tabset}  
## Accuracy
Accuracy is one the way to assess the race variable is in fact helping in a significant way when used to predict a person's recidivism rate.
  
Algorithm|With race | Without race
---------|----------|-------------
Algorithm given|65.7%|None
Decision tree|50.0%|48.9%
Neutral network|66%|65%  
Naïve Baynes|61.8%|55.7% 
KNN|62.4%|62.9%
Stacking|63%|62%
Ensemble|67%|63%    
## Original Algorithm Confusion Matrix  
One of the ways we decided to use to assess how the algorithm is to look at how the false positive rate of the algorithms change as we filtered the data at race. If the algorithm doesn’t not discriminate* against race, we could expect an unchanged false positive rate. 
```{r}
x <- dat_o %>% 
  select(race, two_year_recid, decile_score.1) %>% 
  mutate(highlow = case_when(decile_score.1 > 5 ~ 1,
                             T                  ~ 0))

p_class <- factor(x$highlow, levels = c(1,0))
class_levels <- factor(x$two_year_recid, levels = c(1,0))

re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#ff3f7f', '#ff7f3f'))
F_meas(re$table)
re$overall[1]
re$byClass[1]
re$byClass[2]

y <- dat_o %>% 
  filter(race == 'African-American') %>% 
  select(race, two_year_recid, decile_score.1) %>% 
  mutate(highlow = case_when(decile_score.1 > 5 ~ 1,
                             T                  ~ 0))

p_class <- factor(y$highlow, levels = c(1,0))
class_levels <- factor(y$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
F_meas(re$table)
re$overall[1]
re$byClass[1]
re$byClass[2]

```
Filtered|F1 meansure|Seneitivity|Specificity
---------|----------|-------------
## Other Confusion Matrix
### decision tree  
```{r}
p_class <- factor(rdat$prediction, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
i <- fourfoldplot(re$table, color = c('#ff3f7f', '#ff7f3f'))
p_class <- factor(rdat$drpre, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
j <- fourfoldplot(re$table , color = c('#7fff3f' , '#3fbfff'))
```

### NN  
```{r}
p_class <- factor(frdat$NN, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color =  c('#ff3f7f', '#ff7f3f'))
p_class <- factor(fdat$NN, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
```

### KNN  
```{r}
p_class <- factor(frdat$KNN, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color =  c('#ff3f7f', '#ff7f3f'))
p_class <- factor(fdat$KNN, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
```

### naive bayes  
```{r}
p_class <- factor(frdat$NG, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color =  c('#ff3f7f', '#ff7f3f'))
p_class <- factor(fdat$NG, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
```

### Stacking  
```{r}
p_class <- factor(frdat$Final, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color =  c('#ff3f7f', '#ff7f3f'))
p_class <- factor(fdat$Final, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
```

    
# Conclusions (including business takeaways and action items)  
1.    False positive  
Under development  
2.    Score and accuracy   
Under development  
3.    Limitations  
   We suspect that our data might suffer from an unjust bias because of the self-reinforcing nature of the algorithm. Since the given predicted score is used as an assessment for the judge to decide the sentence of a criminal, which involves how long he/she will be staying in jail. It might, in fact, reinforcing the result of our target (recidivism rate) thinking that the longer a person stays in the justice system(prison), the more likely he/she will end up in a cell again.   
   
# Lessons Learned  
1.    Algorithms are tools  
We realised recidivism is a very tricky study and the more we dig into the topic, the more we see how sometimes human bias could easily be introduced to the data gathering process. A learning algorithm is asked to show the patterns in the data through punishments and reinforcements (error and weights), and when used improperly, could create major misunderstanding and fall into the trap of prejudice and over-generalizations.  
  
