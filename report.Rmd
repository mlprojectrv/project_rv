---
title: "The Recividism rate"
author: "Keith Tung"
date: "April 2, 2019"
output:
  html_document:
    keep_md: TRUE
    TOC_float: TRUE
    code_folding: hide
    theme: united
    fig.height: 12
    fig.width: 12
    message: 'no'
    warning:  'no'
    alignment: center
---

```{r message = FALSE, warning=FALSE}
################################library##############################################
library(tidyverse)
library(readr)
library(ggplot2)
library(ggridges)
library(pander)
library(caret)
################################Read File############################################
dat_o <- read.csv('https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv')
dat <- read_csv('./dt_dat.csv')
rdat <- read_csv('./dt.csv') %>% select(-1)
frdat <- read_csv('./fr_race.csv') %>% select(-1)
fdat <- read_csv('./frw_race.csv') %>% select(-1)
dat_nnn <- read_csv('Song/race2.csv')
```

![](https://s3.amazonaws.com/user-media.venngage.com/470824-9369c5da7d87766af4f57f6d0421e5e9.jpg)  



### Team Info
1. Team members: 
  Keaton Sant, Keith Tung, Juheon Song
2. Data source:
  Data source: Machine bias https://github.com/propublica/compas-analysis/blob/master/compas-scores-two-years.csv
    
# Introduction  
###    The source  
This project is mainly inspired by a statistical study online; in this study, the narrator introduces the reader to an algorithm the justice system in the US is currently using. This algorithm takes in criminal information such as age, gender, race, and criminal records then produces a score for the person’s ‘risk of recidivism’ which would be provided as reference to the judge in deciding the sentence of a criminal; the study contains arguments with various plots and charts that surround the same claim : the algorithm is biased against black criminal.     

###     Our take  

We, as a team, chose to investigate this data that recorded inmates’ information that was used to predict the criminals' recidivism rate before they were sentenced jail time. This data set shows a column with the predicted score and whether these individuals ended up committing a crime again in the 2 year period after they were released from jail.  

###    Our Goals  
There are two main goals for our project:  

*	Examine the claim made by the study, see that the current algorithm is biased
*	Try to create an algorithm hoping to see if race is indeed a helpful variable in predicting recidivism rate.
  
#  Data Preparation  
###    Understanding the data  
Fortunately, the study provided the data we need, and we were able to get our hands on a fairly clean dataset. The data consists of 53 columns and 10 observations.  
  
  
There are a few observations from the data.  
  

### Observation{.tabset}  
#### The converting
To accomplish our tasks, we needed the data to fit in four different machine learning algorithms, namely, Naïve Bayes (classifier), Decision tree (classifier), Neural network (classifier), and lastly Neural Network (regressor) for the ensemble part. The data set contains numeric, categorical and nominal columns with the binary target columne (recidivist or non-recidivist); we decided that we would have to convert our data to fit our models.   

#### Original data(sample of 5)
```{r}
dat_o %>% head(5) %>% print.data.frame()
```
#### Data after wrangling(Decision Tree)
```{r}
dat %>% head(5) %>% print.data.frame()
```
#### Data after wrangleing(Neural Network and Naïve Bayes)
```{r}
dat_nnn %>% head(5) %>% print.data.frame()
```

###    Decisions made{.tabset}  
#### Charges
One of the challenges of the data is the c_charge_desc that stores the description of the crime for what the inmate was charged; there were 437 different charges description in our data with over 7000 observations. We had to do a local encoding for each of them for the Neural Network models.    

#### List of charges  
```{r}
dat_o$c_charge_desc %>% 
  unique() 
```
#### Race   
Since one of our goals is to see if the algorithm is biased against African Americans criminals, we simply convert all the non-black race to 0 and black to 1 (basically a column to 'Isblack'). 



# Mining/learning from the data


### Data analysis{.tabset}  
#### 1  
The graph shows the density ofthe predicted score from the algorithm. We can see a that in all three age groups, african-americans has a higher density beyond the 5.0 in score; with non-african-american criminals having distrabutions closing to the other end. It also shows the differences among the age group, while the algorithm is fairly willing to give a low score to someone in the 'Greater than 45' group; it tends to give a higher score to people that are in the less than 25 more than the other two.
```{r message = FALSE}
dat_o %>% 
  mutate(age_cat = fct_relevel(age_cat, 
                               c('Less than 25',
                                 '25 - 45',
                                 'Greater than 45'))) %>% 
  ggplot() +
  aes(y = age_cat, 
      x = dat_o$decile_score.1, 
      fill = (race == 'African-American')) +
  geom_density_ridges(panel_scaling = F,
                       alpha = 0.35) +
  coord_cartesian(xlim = c(0,10)) +
  scale_fill_brewer(palette = 'Dark2') +
  ggthemes::theme_pander() +
  labs(x = 'predicted score',
       y = 'age group') +
  guides(fill = guide_legend(title = 'African-American', label.position = 'right')) +
  theme(axis.line.x = element_line(linetype = 'dashed', colour = 'Gray'),
        legend.position = c(0.9,0.9))
```

#### 2

The histograms show the predicted scores from the algorithm. Each bar’s color presents if they are recidivist or not. The recidivist bar should distribute to score of 10, and not recidivist bar should place to score of 0 based on the algorithm. In the other races’ plot, we can see that most of the not recidivist criminals of other races are distributed between 0 to 2, and it gets decreased as the predicted scores go higher. However, the recidivist bars go low like not recidivist bars. This states that the algorithm tends to distribute criminals of the other races who are not recidivists. The African American histogram shows that there are more African American recidivists than in the plot of the other races. It is interesting to see how much of the differences there is between African American than all the other races combined.
```{r message = FALSE}
dat_o %>% 
  mutate(sep = case_when(
    race == 'African-American' ~ 'Black',
    race != 'African-American' ~ 'Non-Black'
  )) %>% 
  ggplot() +
  aes(x = dat_o$decile_score.1, fill = dat_o$two_year_recid == 1) +
  geom_histogram(position = 'dodge_2') +
  facet_grid(sep~.) +
  ggthemes::theme_pander() +
  theme(strip.text.y = element_text(size = 12, angle = 0),
        strip.background = element_blank()) +
  scale_fill_brewer(palette = 'Dark2') +
  guides(fill = guide_legend(title = 'recidivist', label.position = 'right')) +
  labs(title = 'The Actual Recidivism Compared to the Predicted Score', x = 'predicted score', y = '') +
  theme(axis.line.x = element_line(linetype = 'dashed', colour = 'Gray'),
        legend.position = c(0.9,0.9)) 
  
```

#### 3
```{r}
dat_o %>% 
  ggplot() +
  aes(y = as.numeric(dat_o$two_year_recid), x = dat_o$decile_score.1) +
  geom_smooth(method = 'glm', method.args = list(family = 'binomial'), se = F, linetype = 'dashed') +
  geom_point() +
  ggthemes::theme_pander() +
  labs(title='The Probability of a Criminal Recidivating', subtitle = 'According to their algorithm\'s ', y = 'probability', x = 'Predicted Score')

dat_o %>% 
  filter(race == 'African-American') %>% 
  ggplot() +
  aes(y = as.numeric(two_year_recid), x = decile_score.1) +
  geom_smooth(method = 'glm', method.args = list(family = 'binomial'), se = F, linetype = 'dashed') +
  geom_point() +
  ggthemes::theme_pander() +
  labs(title='The Probability of an African American Recidivating', y = 'Probability', x = 'Predicted Score')
```

###    The planning  
We mainly used three algorithms for this project, decision tree, neural network, and naïve Baynes. Since we are trying to compare the given predicted score to ours, we were convinced that a regression is best for the task at hand, since the predicted scores are in a scale of 1 to 10. 1 being the inmates will not likely to commit crime in the future and 10 being very likely, our algorithms would suggest a number between 1 and 10 for the predicted, then we would find out how close/far the score is to the target (1 = 10, 0 = 0) compared with the given scores. We also wanted to see if the algorithm is discriminating against each group of people by their colour of skin. A way to find that out is to see the ratio of (false positive) type I error in the non-African-American cases and  African-American cases.  

###    Setting up the environment  
When we were trying the different algorithms, we would run our models in two environments, one with race given as the training data, the other one without race given. We would like to find out how important the race feature is. This means before the ensemble learning, we had 6 different models to building first.  

# Results{.tabset}  
## Accuracy
Accuracy is one the way to assess the race variable is in fact helping in a significant way when used to predict a person's recidivism rate.
  
Algorithm|With race | Without race
---------|----------|-------------
Given Algorithm|65.6%|None
Decision tree|50.6%|49.0%
Neutral network|66%|65%  
Naïve Baynes|61.8%|55.7% 
KNN|62.4%|62.9%
Stacking|63%|67%     
## Confusion Matrix for original algorithm
```{r}
x <- dat_o %>% 
  select(race, two_year_recid, decile_score.1) %>% 
  mutate(highlow = case_when(decile_score.1 > 5 ~ 1,
                             T                  ~ 0))

p_class <- factor(x$highlow, levels = c(1,0))
class_levels <- factor(x$two_year_recid, levels = c(1,0))

re <- confusionMatrix(p_class, class_levels, positive = '1')
fourfoldplot(re$table)

y <- dat_o %>% 
  filter(race == 'African-American') %>% 
  select(race, two_year_recid, decile_score.1) %>% 
  mutate(highlow = case_when(decile_score.1 > 5 ~ 1,
                             T                  ~ 0))

p_class <- factor(y$highlow, levels = c(1,0))
class_levels <- factor(y$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table)
```

Filtered|F1 meansure|Seneitivity|Specificity
---------|----------|-------------|----------
No|0.71|0.77|0.53
Yes|0.64|0.63|0.66  

## Other Confusion Matrix
### decision tree  
```{r}
p_class <- factor(rdat$prediction, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
i <- fourfoldplot(re$table, color = c('#ff3f7f', '#ff7f3f'))
p_class <- factor(rdat$drpre, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
j <- fourfoldplot(re$table , color = c('#7fff3f' , '#3fbfff'))
```

### NN  
```{r}
p_class <- factor(frdat$NN, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color =  c('#ff3f7f', '#ff7f3f'))
p_class <- factor(fdat$NN, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
```

### KNN  
```{r}
p_class <- factor(frdat$KNN, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color =  c('#ff3f7f', '#ff7f3f'))
p_class <- factor(fdat$KNN, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
```

### naive bayes  
```{r}
p_class <- factor(frdat$NG, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color =  c('#ff3f7f', '#ff7f3f'))
p_class <- factor(fdat$NG, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
```

### Stacking  
```{r}
p_class <- factor(frdat$Final, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color =  c('#ff3f7f', '#ff7f3f'))
p_class <- factor(fdat$Final, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
```


    
# Conclusions (including business takeaways and action items)  
1.    Bias
When we compare the confusion matrix  of the our result there is some clues that might suggest African-americans are getting the short end of the stick. A lower specificity indicate that the algorithm is not as forgiving 
2.    Score and accuracy   
Under development  
3.    Limitations  
   We suspect that our data might suffer from an unjust bias because of the self-reinforcing nature of the algorithm. Since the given predicted score is used as an assessment for the judge to decide the sentence of a criminal, which involves how long he/she will be staying in jail. It might, in fact, reinforcing the result of our target (recidivism rate) thinking that the longer a person stays in the justice system(prison), the more likely he/she will end up in a cell again.   
   
# Lessons Learned  
1.    Algorithms are tools  
We realised recidivism is a very tricky study and the more we dig into the topic, the more we see how sometimes human bias could easily be introduced to the data gathering process. A learning algorithm is asked to show the patterns in the data through punishments and reinforcements (error and weights), and when used improperly, could create major misunderstanding and fall into the trap of prejudice and over-generalizations.  

