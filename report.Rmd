---
title: "The Recividism rate"
author: "Keith Tung"
date: "April 2, 2019"
output:
  html_document:
    keep_md: TRUE
    TOC_float: TRUE
    code_folding: hide
    theme: united
    fig.height: 12
    fig.width: 12
    message: 'no'
    warning:  'no'
    alignment: center
---

```{r message = FALSE, warning=FALSE}
################################library##############################################
library(tidyverse)
library(readr)
library(ggplot2)
library(ggridges)
library(pander)
library(caret)
################################Read File############################################
dat_o <- read.csv('https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv')
dat <- read_csv('./dt_dat.csv')
rdat <- read_csv('./dt.csv') %>% select(-1)
frdat <- read_csv('./fr_race.csv') %>% select(-1)
fdat <- read_csv('./frw_race.csv') %>% select(-1)
dat_nnn <- read_csv('Song/race2.csv')
```

![](https://s3.amazonaws.com/user-media.venngage.com/470824-9369c5da7d87766af4f57f6d0421e5e9.jpg)  



### Team Info
1. Team members: 
  Keaton Sant, Keith Tung, Juheon Song
2. Data source:
  Data source: Machine bias https://github.com/propublica/compas-analysis/blob/master/compas-scores-two-years.csv
    
# Introduction  
###    The source  
This project is mainly inspired by a statistical study online; in this study, the narrator introduces the reader to an algorithm the justice system in the US is currently using. This algorithm takes in criminal information such as age, gender, race, and criminal records then produces a score for the person’s ‘risk of recidivism’ which would be provided as reference to the judge in deciding the sentence of a criminal; the study contains arguments with various plots and charts that surround the same claim : the algorithm is biased against black criminal.     

###     Our take  

We, as a team, chose to investigate this data that recorded inmates’ information that was used to predict the criminals' recidivism rate before they were sentenced jail time. This data set shows a column with the predicted score and whether these individuals ended up committing a crime again in the 2 year period after they were released from jail.  

###     Our Goals  
There are two main goals for our project:  

*	Examine the claim made by the study, see that the current algorithm is biased
*	Try to create an algorithm hoping to see if race is indeed a helpful variable in predicting recidivism rate.
  
#  Data Preparation  
###    Understanding the data  
Fortunately, the study provided the data we need, and we were able to get our hands on a fairly clean dataset. The data consists of 53 columns and 10 observations.  
  
  
There are a few observations from the data.  
  

### Observation{.tabset}  
#### The converting
To accomplish our tasks, we needed the data to fit in five different machine learning algorithms, namely, Naïve Bayes (classifier), Decision tree (classifier), Neural Network (classifier), K Nearest Neighbor (Classifier), and stacking. The data set contains numeric and categorical columns with the binary target column "recidivist or non-recidivist".

#### Original data(sample of 5)
```{r}
pander(dat_o %>% head(5))
```
#### Data after wrangling(Categorical)
```{r}
pander(dat %>% head(5))
```
#### Data after wrangleing(Numeric)
```{r}
pander(dat_nnn %>% head(5))
```

###    Decisions made{.tabset}  
#### Charges
One of the challenges of the data is the c_charge_desc that stores the description of the crime for what the inmate was charged; there were 437 different charges description in our data with over 7000 observations. We had to do a local encoding for each of them for the Neural Network models.    

#### List of charges  
```{r}
dat_o$c_charge_desc %>% 
  unique() 
```



# Mining/learning from the data


### Data analysis{.tabset}  
#### 1  
The graph shows the density of the predicted score from the algorithm. We can see that in all three age groups, african-americans have a higher density beyond the 5.0 score; with non-african-american criminals having distributions closing to the other end. It also shows the differences among the age group, while the algorithm is fairly willing to give a low score to someone in the 'Greater than 45' group; it tends to give a higher score to people that are in the less than 25 more than the other two.
```{r message = FALSE, fig.width=8}
dat_o %>% 
  mutate(age_cat = fct_relevel(age_cat, 
                               c('Less than 25',
                                 '25 - 45',
                                 'Greater than 45'))) %>% 
  ggplot() +
  aes(y = age_cat, 
      x = dat_o$decile_score.1, 
      fill = (race == 'African-American')) +
  geom_density_ridges(panel_scaling = F,
                       alpha = 0.35) +
  coord_cartesian(xlim = c(0,10)) +
  scale_fill_brewer(palette = 'Dark2') +
  ggthemes::theme_pander() +
  labs(x = 'predicted score',
       y = 'age group') +
  guides(fill = guide_legend(title = 'African-American', label.position = 'right')) +
  theme(axis.line.x = element_line(linetype = 'dashed', colour = 'Gray'),
        legend.position = c(0.9,0.9))
```

#### 2

The histograms show the predicted scores from the algorithm. Each bar’s color presents if they are recidivist or not. The recidivist bar should distribute to score of 10, and not recidivist bar should place to score of 0 based on the algorithm. In the other races’ plot, we can see that most of the not recidivist criminals of other races are distributed between 0 to 2, and it gets decreased as the predicted scores go higher. However, the recidivist bars go low like not recidivist bars. This states that the algorithm tends to distribute criminals of the other races who are not recidivists. The African American histogram shows that there are more African American recidivists than in the plot of the other races. It is interesting to see how much of the differences there is between African American than all the other races combined.

```{r message = FALSE}
dat_o %>% 
  mutate(sep = case_when(
    race == 'African-American' ~ 'Black',
    race != 'African-American' ~ 'Non-Black'
  )) %>% 
  ggplot() +
  aes(x = dat_o$decile_score.1, fill = dat_o$two_year_recid == 1) +
  geom_histogram(position = 'dodge_2') +
  facet_grid(sep~.) +
  ggthemes::theme_pander() +
  theme(strip.text.y = element_text(size = 12, angle = 0),
        strip.background = element_blank()) +
  scale_fill_brewer(palette = 'Dark2') +
  guides(fill = guide_legend(title = 'recidivist', label.position = 'right')) +
  labs(title = 'The Actual Recidivism Compared to the Predicted Score', x = 'predicted score', y = '') +
  theme(axis.line.x = element_line(linetype = 'dashed', colour = 'Gray'),
        legend.position = c(0.9,0.9)) 
  
```

#### 3
```{r}
dat_o %>% 
  ggplot() +
  aes(y = as.numeric(dat_o$two_year_recid), x = dat_o$decile_score.1) +
  geom_smooth(method = 'glm', method.args = list(family = 'binomial'), se = F, linetype = 'dashed') +
  geom_point() +
  ggthemes::theme_pander() +
  labs(title='The Probability of a Criminal Recidivating', subtitle = 'According to their algorithm\'s ', y = 'probability', x = 'Predicted Score')

dat_o %>% 
  filter(race == 'African-American') %>% 
  ggplot() +
  aes(y = as.numeric(two_year_recid), x = decile_score.1) +
  geom_smooth(method = 'glm', method.args = list(family = 'binomial'), se = F, linetype = 'dashed') +
  geom_point() +
  ggthemes::theme_pander() +
  labs(title='The Probability of an African American Recidivating', y = 'Probability', x = 'Predicted Score')
```

###    The planning  
The main 4 algorithms used for this project are Decision Tree, KNN, Neural Network, and Naïve Baynes. Since we are trying to compare our algoriths to theirs, we are using classification to predict if a criminal who was released from prison would commit a crime within two years after their release date. We wanted to see if the algorithm is discriminating against each group of people by their race. To find this we need to see the ratio of the (false positive) type I error in the non-African-American cases and  African-American cases.  

###    Setting up the environment  
When we were trying the different algorithms, we would run our models in two environments, one with race given as the training data, the other one without race given. We would like to find out how important the race feature is. This means before the ensemble learning, we had 6 different models to building first.  

# Results{.tabset}  
## Accuracy
Accuracy is one the way to assess the race variable is in fact helping in a significant way when used to predict a person's recidivism rate.
  
Algorithm|With race | Without race
---------|----------|-------------
Given Algorithm|65.6%|None
Decision tree|50.6%|49.0%
Neutral network|66%|65%  
Naïve Baynes|61.8%|55.7% 
KNN|62.4%|62.9%
Stacking|63%|67%     
## Confusion Matrix for original algorithm
```{r}
x <- dat_o %>% 
  select(race, two_year_recid, decile_score.1) %>% 
  mutate(highlow = case_when(decile_score.1 > 5 ~ 1,
                             T                  ~ 0))

p_class <- factor(x$highlow, levels = c(1,0))
class_levels <- factor(x$two_year_recid, levels = c(1,0))

re <- confusionMatrix(p_class, class_levels, positive = '1')
fourfoldplot(re$table)

y <- dat_o %>% 
  filter(race == 'African-American') %>% 
  select(race, two_year_recid, decile_score.1) %>% 
  mutate(highlow = case_when(decile_score.1 > 5 ~ 1,
                             T                  ~ 0))

p_class <- factor(y$highlow, levels = c(1,0))
class_levels <- factor(y$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table)
```

Filtered|F1 measure|Seneitivity|Specificity
---------|----------|-------------|----------
No|0.71|0.77|0.53
Yes|0.64|0.63|0.66  

## Confusion Matrix(Decision Tree)  

```{r}
p_class <- factor(rdat$prediction, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
i <- fourfoldplot(re$table, color = c('#ff3f7f', '#ff7f3f'))
p_class <- factor(rdat$drpre, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
j <- fourfoldplot(re$table , color = c('#7fff3f' , '#3fbfff'))
```
 

## Confusion Matrix(Neutral Network)

```{r}
p_class <- factor(frdat$NN, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color =  c('#ff3f7f', '#ff7f3f'))
p_class <- factor(fdat$NN, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
```

## Confusion Matrix(KNN)  

```{r}
p_class <- factor(frdat$KNN, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color =  c('#ff3f7f', '#ff7f3f'))
p_class <- factor(fdat$KNN, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
```

## Confusion Matrix(Naïve Baynes)

```{r}
p_class <- factor(frdat$NG, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color =  c('#ff3f7f', '#ff7f3f'))
p_class <- factor(fdat$NG, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
```

## Confusion Matrix(Stacking)

```{r}
p_class <- factor(frdat$Final, levels = c(1,0))
class_levels <- factor(dat$two_year_recid, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color =  c('#ff3f7f', '#ff7f3f'))
p_class <- factor(fdat$Final, levels = c(1,0))
re <- confusionMatrix(p_class, class_levels)
fourfoldplot(re$table, color = c('#7fff3f' , '#3fbfff'))
```

## Table
Algorithm and dataset|F1 measure|Seneitivity|Specificity
---------|----------|-------------|----------
Decesion Tree(w/ race)|0.68|0.96|0.28
Decesion Tree(w/o race)|0.89|0.95|0.35
Neutral Network(w/ race)|0.59|0.52|0.8
Neutral Network(w/o race)|0.61|0.58|0.74
KNN (w/ race)|0.73|0.71|0.80
KNN (w/o race)|0.72|0.7|0.8
Naïve Baynes(w/ race)|0.37|0.25|0.92
Naïve Baynes(w/o race)|0.36|0.24|0.93
Stacking(w/ race)|0.6|0.69|0.51
Stacking(w/o race)|0.61|0.58|0.74
    
# Conclusions (including business takeaways and action items)
1.    The Decision Tree
We decided not to use the Decision Tree in the Stacking algorithm
2.    Bias  
When we compare the confusion matrix  of the our result there is some clues that might suggest African-americans are getting the short end of the stick. A lower specificity indicate that the algorithm is not as forgiving and as good at excluding true negatives from the data. However, it also shows a seneitivity of .77, a better score that the overall one. With a lower F1 measure, our do see a drop of performance in prediction for african-american. 
3.    Score and accuracy   
The reason why we compare the two different accuracy scores from each algorithm is to study whether the race would affect the result or not. From the accuracy score table, we can see that there are no significant differences between with and without race score. This concludes that race in criminal data does not affect the result. 
4.    Limitations  
We suspect that our data might suffer from an unjust bias because of the self-reinforcing nature of the algorithm. Since the given predicted score is used as an assessment for the judge to decide the sentence of a criminal, which involves how long he/she will be staying in jail. It might, in fact, reinforcing the result of our target (recidivism rate) thinking that the longer a person stays in the justice system(prison), the more likely he/she will end up in a cell again.   
5.    The true question
Although we did spend a lot of time on trying 
   
# Lessons Learned  
1.    Algorithms are tools  
We realised recidivism is a very tricky study and the more we dig into the topic, the more we see how sometimes human bias could easily be introduced to the data gathering process. A learning algorithm is asked to show the patterns in the data through punishments and reinforcements (error and weights), and when used improperly, could create major misunderstanding and fall into the trap of prejudice and over-generalizations.  

2.    The success of a machine learning algorithm does not rely on how much hidden patterns are found by it only.
When we talk about how problems could be solved by machine learning, one often mentioned reason is how machine learning studies patterns that are hidden or hard to observed by human. Machine learning algorithms record and remember those subtle changes and trends, then utilizes the data to predict or make judgments base on the given information. One way we assess the performance of an algorithm is to see if it is gaining more insight, discovering hidden patterns. However, the success of it does not reply only on the insights gained; it depends on how much the machine could think more ‘human-like’. One of the biggest downsides of a machine-driven algorithm is that it does not take into account things that could matter a lot, or things that we, as human, treasure. In the case of predicting recidivism rate, it would be very difficult to assess someone’s remorse over the crimes they committed, or their will to change and repent, or the words and reasonings they used in their defense, along with many factors that could be considered directly connected to someone’s recidivism rate. We think this one of the reasons why our algorithms could not break the 70% line in accuracy 




